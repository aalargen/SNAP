{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "\n",
    "%cd /mnt/home/acanatar/jupyter/SNAP\n",
    "\n",
    "data_root = './data/'\n",
    "os.makedirs(data_root, exist_ok=True)\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dimensionality\n",
    "importlib.reload(dimensionality)\n",
    "importlib.reload(dimensionality.models)\n",
    "importlib.reload(dimensionality.wrapper)\n",
    "importlib.reload(dimensionality.metrics)\n",
    "importlib.reload(dimensionality.experiment)\n",
    "importlib.reload(dimensionality.brainscore_data)\n",
    "importlib.reload(dimensionality.regression_utils)\n",
    "importlib.reload(dimensionality.utils)\n",
    "\n",
    "from dimensionality.wrapper import TorchWrapper\n",
    "\n",
    "from dimensionality.experiment import Experiment\n",
    "from dimensionality.brainscore_data import get_neural_data\n",
    "\n",
    "import dimensionality.models as models\n",
    "from dimensionality.regression_utils import regression_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region='V1'\n",
    "dataset = 'dicarlo'\n",
    "image_type = 'original'  # Only matters for Cadena dataset\n",
    "\n",
    "data_loader_neural, images, labels = get_neural_data(region=region, dataset=dataset, image_type=image_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brainscore Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer:   6%|â–Œ         | 1/18 [00:17<04:56, 17.43s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/home/acanatar/jupyter/SNAP/experiments.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bccnvnc/mnt/home/acanatar/jupyter/SNAP/experiments.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# Compute metrics\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bccnvnc/mnt/home/acanatar/jupyter/SNAP/experiments.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m metric_kwargs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mdebug\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bccnvnc/mnt/home/acanatar/jupyter/SNAP/experiments.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m                  \u001b[39m'\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1e-8\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bccnvnc/mnt/home/acanatar/jupyter/SNAP/experiments.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m                  \u001b[39m'\u001b[39m\u001b[39mepsilon\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1e-14\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bccnvnc/mnt/home/acanatar/jupyter/SNAP/experiments.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m                  } \u001b[39m|\u001b[39m regression_kwargs\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bccnvnc/mnt/home/acanatar/jupyter/SNAP/experiments.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m exp_metrics \u001b[39m=\u001b[39m exp\u001b[39m.\u001b[39;49mcompute_metrics(images\u001b[39m=\u001b[39;49mimages, labels\u001b[39m=\u001b[39;49mlabels, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmetric_kwargs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bccnvnc/mnt/home/acanatar/jupyter/SNAP/experiments.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m layers \u001b[39m=\u001b[39m exp_metrics[\u001b[39m'\u001b[39m\u001b[39mlayers\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bccnvnc/mnt/home/acanatar/jupyter/SNAP/experiments.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m np\u001b[39m.\u001b[39msavez(data_fname, exp_metrics\u001b[39m=\u001b[39mexp_metrics, layers\u001b[39m=\u001b[39mlayers, metric_kwargs\u001b[39m=\u001b[39mmetric_kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ffcv/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/jupyter/SNAP/dimensionality/experiment.py:97\u001b[0m, in \u001b[0;36mExperiment.compute_metrics\u001b[0;34m(self, images, labels, activations, max_points, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mfor\u001b[39;00m metric_fn \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric_fns:\n\u001b[1;32m     96\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mComputing \u001b[39m\u001b[39m{\u001b[39;00mmetric_fn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 97\u001b[0m     data_dict[metric_fn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m] \u001b[39m=\u001b[39m metric_fn(activations\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivations, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmetric_kwargs)\n\u001b[1;32m     99\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMetric Computation completed!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m \u001b[39mreturn\u001b[39;00m data_dict\n",
      "File \u001b[0;32m~/miniconda3/envs/ffcv/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/jupyter/SNAP/dimensionality/regression_utils.py:318\u001b[0m, in \u001b[0;36mregression_metric\u001b[0;34m(activations, labels, spectrum_dict, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m weights \u001b[39m=\u001b[39m spectrum_dict[\u001b[39m'\u001b[39m\u001b[39mcent\u001b[39m\u001b[39m'\u001b[39m][layer_key][\u001b[39m'\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m'\u001b[39m][label_key]\n\u001b[1;32m    317\u001b[0m theory \u001b[39m=\u001b[39m gen_error_theory(eigs, weights, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 318\u001b[0m errors \u001b[39m=\u001b[39m regression(layer_act, y, eigs, weights, cent\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    319\u001b[0m errors \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m theory\n\u001b[1;32m    320\u001b[0m reg_responses_cent[layer_key][label_key] \u001b[39m=\u001b[39m errors\n",
      "File \u001b[0;32m~/miniconda3/envs/ffcv/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/jupyter/SNAP/dimensionality/regression_utils.py:229\u001b[0m, in \u001b[0;36mregression\u001b[0;34m(feat, y, eigs, weights, pvals, cent, num_points, num_trials, reg, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[39melse\u001b[39;00m:  \u001b[39m# Underdetermined lstsq (push through identity, K_tr = feat @ feat.T)\u001b[39;00m\n\u001b[1;32m    228\u001b[0m         Id \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meye(p, device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdouble)\n\u001b[0;32m--> 229\u001b[0m         y_hat \u001b[39m=\u001b[39m K[:, idx] \u001b[39m@\u001b[39m torch\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv(K[idx, :][:, idx] \u001b[39m+\u001b[39;49m p\u001b[39m*\u001b[39;49mlamb\u001b[39m*\u001b[39;49mId) \u001b[39m@\u001b[39m y_tr\n\u001b[1;32m    231\u001b[0m \u001b[39mexcept\u001b[39;00m torch\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mLinAlgError:\n\u001b[1;32m    232\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mLinAlgErr, Computing regression with pseudo-inverse (slow)\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = 'dicarlo'\n",
    "image_type = 'original'  # Only matters for Cadena dataset\n",
    "\n",
    "regionNames = ['V1',\n",
    "               'V2',\n",
    "               'V4',\n",
    "               'IT'\n",
    "               ]\n",
    "\n",
    "activation_pooling = [None,\n",
    "                      #   'MaxPool_(1,1)',\n",
    "                      #   'AvgPool_(1,1)',\n",
    "                      ]\n",
    "\n",
    "rand_proj_dim = None\n",
    "pretrained = {True: 'pretrained',\n",
    "              False: 'untrained'\n",
    "              }\n",
    "\n",
    "\n",
    "modelNames = ['alexnet', 'resnet18', 'resnet50',\n",
    "              # 'robust_resnet50_l2_3', 'moco_resnet50',\n",
    "              'barlowtwins', 'robust_resnet50_linf_4'\n",
    "              ]\n",
    "\n",
    "\n",
    "for region in regionNames:\n",
    "\n",
    "    data_loader_neural, images, labels = get_neural_data(region=region, dataset=dataset, image_type=image_type)\n",
    "\n",
    "    for model_name in modelNames:\n",
    "\n",
    "        for pooling in activation_pooling:\n",
    "            for trained in [True, False]:\n",
    "\n",
    "                data_dir = os.path.join(data_root, f\"data_{pooling}_RandProj_{rand_proj_dim}\")\n",
    "                data_fname = os.path.join(data_dir, f\"{region}_data_{model_name}_{pretrained[trained]}.npz\")\n",
    "                os.makedirs(data_dir, exist_ok=True)\n",
    "                print(data_fname)\n",
    "\n",
    "                # Get the model\n",
    "                model_kwargs = {'name': model_name,\n",
    "                                'pretrained': trained,\n",
    "                                'device': device}\n",
    "                model, layers, identifier = models.get_model(**model_kwargs)\n",
    "                model_wrapped = TorchWrapper(model, layers=layers, identifier=identifier, activation_pooling=pooling)\n",
    "\n",
    "                # Create the Experiment Class and pass additional metrics\n",
    "                regression_kwargs = {'num_trials': 5,\n",
    "                                     'reg': 1e-14,\n",
    "                                     'num_points': 5,\n",
    "                                     }\n",
    "\n",
    "                metric_fns = [regression_metric]\n",
    "                exp = Experiment(model_wrapped, metric_fns=metric_fns, rand_proj_dim=rand_proj_dim)\n",
    "\n",
    "                # Extract the activations of the layers passed above using data_loader (only uses the inputs)\n",
    "                exp.get_activations(data_loader_neural())\n",
    "\n",
    "                # Compute metrics\n",
    "                metric_kwargs = {'debug': False,\n",
    "                                 'threshold': 1-1e-8,\n",
    "                                 'epsilon': 1e-14\n",
    "                                 } | regression_kwargs\n",
    "\n",
    "                exp_metrics = exp.compute_metrics(images=images, labels=labels, **metric_kwargs)\n",
    "                layers = exp_metrics['layers']\n",
    "\n",
    "                np.savez(data_fname, exp_metrics=exp_metrics, layers=layers, metric_kwargs=metric_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda (ffcv)",
   "language": "python",
   "name": "ffcv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "646a38c27b25f91c7f2c209818123b42f39f35e324f4a627b8ac987db1a3b2a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
