{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd '/content/drive/MyDrive/SNAP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "\n",
    "data_root = './data/'\n",
    "processed_data_root = os.path.join(data_root, 'processed/')\n",
    "figures_root = os.path.join(data_root, 'figures/')\n",
    "\n",
    "os.makedirs(processed_data_root, exist_ok=True)\n",
    "os.makedirs(figures_root, exist_ok=True)\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dimensionality.data_utils import DataProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'dicarlo'\n",
    "image_type = 'original'  # Only matters for Cadena dataset\n",
    "\n",
    "regionNames = ['V1',\n",
    "               'V2',\n",
    "               #  'V4',\n",
    "               #  'IT'\n",
    "               ]\n",
    "\n",
    "activation_pooling = [\"None\",\n",
    "                      #   'MaxPool_(1,1)',\n",
    "                      #   'AvgPool_(1,1)',\n",
    "                      ]\n",
    "\n",
    "rand_projections = [\"None\",\n",
    "                    #  \"8000\",\n",
    "                    # \"12000\",\n",
    "                    ]\n",
    "pretrained = {True: 'pretrained',\n",
    "              False: 'untrained'\n",
    "              }\n",
    "\n",
    "\n",
    "modelNames = ['alexnet', 'resnet18',\n",
    "              ]\n",
    "\n",
    "\n",
    "pooling_list = []\n",
    "for item in product(activation_pooling, rand_projections):\n",
    "    pooling_list += [\"_RandProj_\".join(item)]\n",
    "activation_pooling = pooling_list.copy()\n",
    "\n",
    "\n",
    "Data = DataProcess(data_root, activation_pooling, regionNames, modelNames, pretrained)\n",
    "dfs_all = Data.get_dataframe(load=False, save_all_data_pckl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = True\n",
    "sort_coord = 'final_scores'\n",
    "threshold = 0.99\n",
    "\n",
    "region_list = Data.region_list\n",
    "pooling_list = Data.pooling_list\n",
    "model_list = Data.model_list\n",
    "\n",
    "for region in region_list:\n",
    "    for pooling in pooling_list:\n",
    "        print(region, pooling)\n",
    "        processed_data_name = processed_data_root + f'{region}_{pooling}_{pretrained[trained]}.npz'\n",
    "\n",
    "        all_data_kwargs = dict(sort_coord=sort_coord,\n",
    "                               trained=trained,\n",
    "                               region_list=[region],\n",
    "                               pooling_list=[pooling],\n",
    "                               model_list=model_list,\n",
    "                               eff_dim_cutoff=0,\n",
    "                               threshold=threshold,\n",
    "                               )\n",
    "        all_reg_hist, all_processed_data = Data.get_all_data(**all_data_kwargs)\n",
    "        all_reg_hist = all_reg_hist[region][pooling]\n",
    "        all_processed_data = all_processed_data[region][pooling]\n",
    "\n",
    "        np.savez(processed_data_name, \n",
    "                 all_reg_hist=all_reg_hist,\n",
    "                 all_processed_data=all_processed_data, \n",
    "                 all_data_kwargs=all_data_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = False\n",
    "sort_coord = 'final_scores'\n",
    "threshold = 0.99\n",
    "\n",
    "region_list = Data.region_list\n",
    "pooling_list = Data.pooling_list\n",
    "model_list = Data.model_list\n",
    "\n",
    "for region in region_list:\n",
    "    for pooling in pooling_list:\n",
    "        print(region, pooling)\n",
    "        processed_data_name = processed_data_root + f'{region}_{pooling}_{pretrained[trained]}.npz'\n",
    "\n",
    "        all_data_kwargs = dict(sort_coord=sort_coord,\n",
    "                               trained=trained,\n",
    "                               region_list=[region],\n",
    "                               pooling_list=[pooling],\n",
    "                               model_list=model_list,\n",
    "                               eff_dim_cutoff=0,\n",
    "                               threshold=threshold,\n",
    "                               )\n",
    "        try:\n",
    "            all_reg_hist, all_processed_data = Data.get_all_data(**all_data_kwargs)\n",
    "            all_reg_hist = all_reg_hist[region][pooling]\n",
    "            all_processed_data = all_processed_data[region][pooling]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        np.savez(processed_data_name, \n",
    "                 all_reg_hist=all_reg_hist,\n",
    "                 all_processed_data=all_processed_data, \n",
    "                 all_data_kwargs=all_data_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda (ffcv)",
   "language": "python",
   "name": "ffcv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
